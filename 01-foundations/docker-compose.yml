version: '3.8'

services:
  # FastAPI Backend
  api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - LLM_MODEL=${LLM_MODEL:-gpt-4}
      - LLM_API_KEY=${LLM_API_KEY}
      - VECTOR_STORE_TYPE=${VECTOR_STORE_TYPE:-faiss}
      - VECTOR_INDEX_PATH=${VECTOR_INDEX_PATH:-./data/faiss_index}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
      - API_HOST=${API_HOST:-0.0.0.0}
      - API_PORT=${API_PORT:-8000}
      - CHUNK_SIZE=${CHUNK_SIZE:-1000}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP:-200}
      - MAX_TOKENS=${MAX_TOKENS:-1000}
      - TEMPERATURE=${TEMPERATURE:-0.1}
      - DEBUG=${DEBUG:-true}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./data:/app/data
      - ./app:/app/app
      - ./src:/app/src
    depends_on:
      - web
    networks:
      - rag-network

  # React Frontend
  web:
    build:
      context: ./web
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
      - REACT_APP_ENVIRONMENT=development
    volumes:
      - ./web/src:/app/src
      - ./web/public:/app/public
    networks:
      - rag-network

networks:
  rag-network:
    driver: bridge

volumes:
  data:
